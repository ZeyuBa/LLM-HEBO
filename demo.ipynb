{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization with GPT-3.5/4 and HEBO\n",
    "We will start by setting up the environment and necessary configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Setup\n",
    "import os\n",
    "\n",
    "# os.environ['HTTP_PROXY'] = '127.0.0.1:7890'\n",
    "# os.environ['HTTPS_PROXY'] = '127.0.0.1:7890'\n",
    "import datetime\n",
    "import functools\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "from pathlib import Path\n",
    "import json_repair\n",
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from loguru import logger\n",
    "\n",
    "# Load environment variables\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# Set ROOT_PATH and other configurations\n",
    "ROOT_PATH = str(Path('.').resolve())\n",
    "print('ROOT_PATH: ', ROOT_PATH)\n",
    "sys.path.insert(0, ROOT_PATH)\n",
    "\n",
    "import prompt_utils\n",
    "\n",
    "_OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "_OPTIMIZER = \"gpt-3.5-turbo\"\n",
    "openai_api_key = _OPENAI_API_KEY\n",
    "\n",
    "if _OPTIMIZER in {\"gpt-3.5-turbo\", \"gpt-4o\"}:\n",
    "    openai.api_key = openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Logging\n",
    "We will now configure the optimization parameters and set up logging for debugging and tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization configuration\n",
    "num_points = 50\n",
    "max_num_steps = 3\n",
    "num_reps = 2\n",
    "max_num_pairs = 20\n",
    "num_generated_points_in_each_step = 8\n",
    "\n",
    "# Set the optimizer configurations\n",
    "optimizer_llm_name = _OPTIMIZER\n",
    "optimizer_gpt_max_decode_steps = 1024\n",
    "optimizer_gpt_temperature = 1.0\n",
    "\n",
    "# Create the result directory\n",
    "datetime_str = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "save_folder = os.path.join(ROOT_PATH, \"outputs\", \"optimization-results\", f\"llm_hebo-o-{optimizer_llm_name}-{datetime_str}/\")\n",
    "os.makedirs(save_folder)\n",
    "logger.add(save_folder + \"log.log\", format=\"{time} {level} {message}\", level=\"DEBUG\")\n",
    "print(f\"Result directory:\\n{save_folder}\")\n",
    "\n",
    "# Set optimizer LLM dictionary\n",
    "optimizer_llm_dict = {\n",
    "    \"max_decode_steps\": optimizer_gpt_max_decode_steps,\n",
    "    \"temperature\": optimizer_gpt_temperature,\n",
    "    \"batch_size\": 1\n",
    "}\n",
    "\n",
    "import asyncio\n",
    "\n",
    "call_optimizer_server_func = functools.partial(\n",
    "    prompt_utils.call_openai_server_func,\n",
    "    model=optimizer_llm_name,\n",
    "    max_decode_steps=optimizer_gpt_max_decode_steps,\n",
    "    temperature=optimizer_gpt_temperature,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Optimizer Server\n",
    "Before proceeding with the optimization process, let's test the optimizer server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the optimizer server\n",
    "print(\"\\n======== Testing the optimizer server ===========\")\n",
    "optimizer_test_output = asyncio.run(call_optimizer_server_func(\n",
    "    \"Does the sun rise from the north? Just answer yes or no.\",\n",
    "    temperature=1.0\n",
    "))\n",
    "print(f\"Optimizer test output: {optimizer_test_output}\")\n",
    "print(\"Finished testing the optimizer server.\")\n",
    "print(\"\\n=================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Settings and Initialization\n",
    "Next, we will load the benchmark settings and initialize the optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpobench.util.openml_data_manager import get_openmlcc18_taskids\n",
    "from hpobench.benchmarks.ml.xgboost_benchmark_old import XGBoostBenchmark as Benchmark\n",
    "import time\n",
    "\n",
    "task_ids = get_openmlcc18_taskids()\n",
    "task_no, task_id = 0, task_ids[0]\n",
    "other_info = {}\n",
    "\n",
    "# Initialize tasks and benchmarks\n",
    "for task_no, task_id in enumerate(task_ids[:2]):\n",
    "    print(f'#################### TASK {task_no + 1} of {len(task_ids)}: Task-Id: {task_id} ###################')\n",
    "    benchmark = Benchmark(task_id=task_id)\n",
    "    if benchmark:\n",
    "        start = time.time()\n",
    "        cs = benchmark.get_configuration_space()\n",
    "        results = []\n",
    "        default_bounds = []\n",
    "        print(\"Hyperparameter default bounds:\")\n",
    "        for hyperparameter in list(cs.values()):\n",
    "            name = hyperparameter.name\n",
    "            lower = hyperparameter.lower\n",
    "            upper = hyperparameter.upper\n",
    "            log = hyperparameter.log\n",
    "            check_int = True if \"check_int\" in dir(hyperparameter) else False\n",
    "            if log:\n",
    "                lower = (math.log(lower, 2))\n",
    "                upper = (math.log(upper, 2))\n",
    "            default_bounds.append((lower, upper))\n",
    "            other_info[name] = [log, check_int]\n",
    "            print(f\"{name}: Lower = {lower}, Upper = {upper}, Check_int = {check_int}, Log_sample = {log}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(type(benchmark).__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "Here, we define the utility functions that will be used throughout the optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hebo.optimizers.hebo import HEBO\n",
    "from hebo.design_space.design_space import DesignSpace\n",
    "from tqdm import tqdm\n",
    "from banks import Prompt\n",
    "\n",
    "# Utility functions\n",
    "def evaluate_loss(benchmark, space_list, fidelity):\n",
    "    def preprocess_func(df):\n",
    "        return_dict = {}\n",
    "        for key in df.columns:\n",
    "            value = df[key].iloc[0]\n",
    "            if isinstance(df[key].iloc[0], np.int64):\n",
    "                value = int(df[key].iloc[0])\n",
    "            elif isinstance(df[key].iloc[0], np.float64):\n",
    "                value = float(df[key].iloc[0])\n",
    "            return_dict[key.split('_log')[0]] = 2.0 ** value if '_log' in key else value\n",
    "        return return_dict\n",
    "\n",
    "    def objective(df):\n",
    "        config = preprocess_func(df)\n",
    "        result_dict = benchmark.objective_function(config, fidelity=fidelity)\n",
    "        return result_dict\n",
    "\n",
    "    logger.info(space_list)\n",
    "    sp = DesignSpace().parse(space_list)\n",
    "    opt = HEBO(sp, rand_sample=4)\n",
    "\n",
    "    for i in tqdm(range(10)):\n",
    "        try:\n",
    "            rec = opt.suggest(n_suggestions=5)\n",
    "            result_dict = objective(rec)\n",
    "            valid_loss = result_dict['function_value']\n",
    "            train_loss = result_dict['info']['train_loss']\n",
    "            y = np.array([-valid_loss], dtype=np.float64)\n",
    "            opt.observe(rec, y)\n",
    "        except Exception as e:\n",
    "            logger.debug(e)\n",
    "            continue\n",
    "        logger.info('After %d iterations, best obj is %.2f' % (i, -opt.best_y))\n",
    "    try:\n",
    "        best_config = preprocess_func(opt.best_x)\n",
    "        print(\"Best params is: \", best_config)\n",
    "        result_dict_test = benchmark.objective_function_test(best_config)\n",
    "        test_loss = result_dict_test['function_value']\n",
    "\n",
    "        return {\n",
    "            'configuration': best_config,\n",
    "            'fidelity': fidelity,\n",
    "            'test_loss': -np.round(test_loss, 3),\n",
    "            'valid_loss': valid_loss,\n",
    "            'train_loss': train_loss\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.debug(e)\n",
    "        return {}\n",
    "\n",
    "def gen_meta_prompt(bound_info, test_loss, old_value_pairs_set, max_num_pairs=100):\n",
    "    bound_names = bound_info.keys()\n",
    "    info = tuple((('bound_range', v['bound_range']),\n",
    "                  ('is_log_sample', v['is_log_sample']),\n",
    "                  ('is_int', v['is_int']))\n",
    "                 for v in bound_info.values())\n",
    "    old_value_pairs_set.add((info, test_loss))\n",
    "\n",
    "    old_value_pairs = list(old_value_pairs_set)\n",
    "    old_value_pairs = sorted(old_value_pairs, key=lambda x: -x[1])[-max_num_pairs:]\n",
    "\n",
    "    old_value_pairs_substr = \"\"\n",
    "    for i, pair in enumerate(old_value_pairs):\n",
    "        old_value_pairs_substr += f\"\\nSuggestion {i}: \"\n",
    "        infos, test_loss = pair\n",
    "        for name, info in zip(bound_names, infos):\n",
    "            old_value_pairs_substr += f\"{name} : \"\n",
    "            old_value_pairs_substr += '( ' + ', '.join([f'{key}: {value}' for key, value in info]) + '), '\n",
    "        old_value_pairs_substr += f' test loss: {test_loss}'\n",
    "\n",
    "    meta_prompt = \"\"\"\n",
    "    As an ML engineer, your task is to provide recommended lower and upper bounds for each hyperparameter in the {algo.name} algorithm. You already have reference data on some ranges and the corresponding test loss for these bounds, with the parameter bounds organized in descending order based on their test loss, where lower values indicate better performance. Analyze each hyperparameter to determine reasonable ranges that optimize model performance, ensuring these bounds are grounded in empirical evidence or established best practices. Your insights will be crucial for refining and optimizing the tuning process for {algo.name} models.\n",
    "  Here are some previously suggested ranges and their performance:\n",
    "    \"\"\".strip()\n",
    "    meta_prompt += \"\\n\\n\"\n",
    "    meta_prompt += old_value_pairs_substr.strip()\n",
    "    meta_prompt += \"\\n\\n\"\n",
    "    meta_prompt += \"\"\"\n",
    "    Please provide a new set of recommended lower and upper bounds for each hyperparameter, ensuring that these ranges are different from any previously suggested ranges. Additionally, ensure that the valid loss value associated with these new ranges is lower than any previously mentioned values. Do not write code. \n",
    "  Your output must follow this json format:\n",
    "    \"\"\".strip()\n",
    "    prompt_template = '''\n",
    "  {\n",
    "    {% for hyper_param in hyper_params_l %}\n",
    "    \"{{ hyper_param }}\": {\n",
    "        \"lower_bound\": \"your lower_bound here\",\n",
    "        \"upper_bound\": \"your upper_bound here\"\n",
    "    },\n",
    "\n",
    "    {% endfor %}\n",
    "  }\n",
    "    '''\n",
    "    p=Prompt(prompt_template)\n",
    "    meta_prompt+=p.text({\"hyper_params_l\": list(bound_info.keys())})\n",
    "    meta_prompt+='''\n",
    "where lower_bound and upper_bound are all numerical values. \n",
    "\n",
    "Answer:\n",
    "```json\n",
    "  '''\n",
    "    return meta_prompt\n",
    "\n",
    "def extract_string(input_string):\n",
    "  raw_result=input_string.split('```')[0]\n",
    "  return raw_result\n",
    "\n",
    "def parse_output(extracted_output):\n",
    "\n",
    "  if not extracted_output:\n",
    "    return\n",
    "  bounds = []\n",
    "  try:\n",
    "    bounds_dict=eval(extracted_output)\n",
    "  except:\n",
    "    good_json_string = json_repair.repair_json(extracted_output, skip_json_loads=True)\n",
    "    bounds_dict =json.loads(good_json_string)\n",
    "  for param_name, range in bounds_dict.items():\n",
    "      lower_bound=eval(range['lower_bound']) if isinstance(range['lower_bound'],str) else range['lower_bound']\n",
    "      upper_bound=eval(range['upper_bound']) if isinstance(range['upper_bound'],str) else range['upper_bound']\n",
    "      bounds.append((lower_bound,upper_bound))\n",
    "  return bounds\n",
    "def process_output(bounds,other_info):\n",
    "  space_list=[]\n",
    "  bound_info={}\n",
    "  for hyper_param_info, bound in zip(other_info.items(),bounds):\n",
    "    param_name,param_info=hyper_param_info\n",
    "    if param_info[0]: # is_log_sample\n",
    "      space_dict = {\n",
    "          'name' : param_name+'_log', \n",
    "          'type' : 'int', \n",
    "          'lb' : bound[0], \n",
    "          'ub' : bound[1],\n",
    "          }\n",
    "      bound_info[param_name]={\n",
    "        'bound_range': (bound[0],bound[1]), \"is_log_sample\": param_info[0], \"is_int\": param_info[1]\n",
    "          }\n",
    "    else:\n",
    "      if param_info[1]: # is_int\n",
    "        space_dict = {\n",
    "          'name' : param_name, \n",
    "          'type' : 'int', \n",
    "          'lb' : int(bound[0]),\n",
    "          'ub' : int(bound[1])}\n",
    "        bound_info[param_name]={\n",
    "        'bound_range': (int(bound[0]),int(bound[1])), \"is_log_sample\": param_info[0], \"is_int\": param_info[1]\n",
    "          }\n",
    "\n",
    "      else:\n",
    "        space_dict = {\n",
    "        'name' : param_name, \n",
    "        'type' : 'num', \n",
    "        'lb' : bound[0], \n",
    "        'ub' : bound[1]} \n",
    "        bound_info[param_name]={\n",
    "        'bound_range': (bound[0],bound[1]), \"is_log_sample\": param_info[0], \"is_int\": param_info[1]\n",
    "          }\n",
    "\n",
    "    space_list.append(space_dict)\n",
    "  return bound_info,space_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Optimization Process\n",
    "We will now run the optimization process using the configurations and utility functions defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_dict = dict()\n",
    "results_dict = dict()\n",
    "num_convergence_steps = []\n",
    "\n",
    "for i_rep in range(num_reps):\n",
    "    found_optimal = False\n",
    "    print(f\"\\nRep {i_rep}:\")\n",
    "    \n",
    "    # Generate the starting points\n",
    "    init_bounds = default_bounds\n",
    "    init_fidelity = {'n_estimators': 8, 'dataset_fraction': 0.4}\n",
    "\n",
    "    configs_dict_single_rep = {\n",
    "        \"optimizer_llm_configs\": optimizer_llm_dict,\n",
    "        \"init_bounds\": init_bounds,\n",
    "        \"max_num_steps\": max_num_steps,\n",
    "        \"max_num_pairs\": max_num_pairs,\n",
    "        \"num_generated_points_in_each_step\": num_generated_points_in_each_step,\n",
    "    }\n",
    "    configs_dict[i_rep] = configs_dict_single_rep\n",
    "    configs_json_path = os.path.join(save_folder, \"configs.json\")\n",
    "    print(f\"Saving configs to\\n{configs_json_path}\")\n",
    "    with open(configs_json_path, \"w\") as f:\n",
    "        json.dump(configs_dict, f, indent=4)\n",
    "\n",
    "    old_value_pairs_set = set()\n",
    "    old_value_pairs_with_i_step = []\n",
    "    meta_prompts_dict = dict()\n",
    "    raw_outputs_dict = dict()\n",
    "    init_space_list = []\n",
    "    bound_info, init_space_list = process_output(init_bounds, other_info)\n",
    "    init_test_loss = evaluate_loss(benchmark, init_space_list, init_fidelity)['test_loss']\n",
    "    bound_range = tuple([v['bound_range'] for v in bound_info.values()])\n",
    "    old_value_pairs_with_i_step.append((bound_range, init_test_loss, -1))\n",
    "\n",
    "    print(\"\\n================ Run Optimization ==============\")\n",
    "\n",
    "    results_json_path = os.path.join(save_folder, \"results.json\")\n",
    "    print(f\"Saving results to\\n{results_json_path}\")\n",
    "    test_loss = init_test_loss\n",
    "    for i_step in range(max_num_steps):\n",
    "        print(f\"\\nStep {i_step}:\")\n",
    "        meta_prompt = gen_meta_prompt(bound_info, test_loss, old_value_pairs_set, max_num_pairs=max_num_pairs)\n",
    "\n",
    "        if not i_step % 5:\n",
    "            print(\"\\n=================================================\")\n",
    "        meta_prompts_dict[i_step] = meta_prompt\n",
    "\n",
    "        # Generate points\n",
    "        remaining_num_points_to_generate = num_generated_points_in_each_step\n",
    "        raw_outputs = []\n",
    "        while remaining_num_points_to_generate > 0:\n",
    "            raw_outputs += asyncio.run(call_optimizer_server_func(meta_prompt))\n",
    "            remaining_num_points_to_generate -= optimizer_llm_dict[\"batch_size\"]\n",
    "        raw_outputs = raw_outputs[:num_generated_points_in_each_step]\n",
    "        raw_outputs_dict[i_step] = raw_outputs\n",
    "        parsed_outputs = []\n",
    "        for string in raw_outputs:\n",
    "            try:\n",
    "                parsed_output = parse_output(extract_string(string))\n",
    "                if parsed_output is not None:\n",
    "                    parsed_outputs.append(parsed_output)\n",
    "            except Exception as e:\n",
    "                logger.debug(e, string)\n",
    "        parsed_outputs = [tuple(item) for item in parsed_outputs]\n",
    "        print(f\"Proposed points: {parsed_outputs}\")\n",
    "\n",
    "        single_step_values = []\n",
    "        for parsed_bounds in parsed_outputs:\n",
    "            bound_info, space_list = process_output(parsed_bounds, other_info)\n",
    "            bound_range = tuple([v['bound_range'] for v in bound_info.values()])\n",
    "            loss = evaluate_loss(benchmark, space_list, init_fidelity)\n",
    "            if 'test_loss' in loss:\n",
    "                test_loss=loss['test_loss']\n",
    "                single_step_values.append(test_loss)\n",
    "                bound_names=bound_info.keys()\n",
    "                info=tuple((('bound_range',v['bound_range']),\n",
    "                        ('is_log_sample',v['is_log_sample']),\n",
    "                        ('is_int',v['is_int']))\n",
    "                        for v in bound_info.values())\n",
    "            old_value_pairs_set.add((info, test_loss))\n",
    "            old_value_pairs_with_i_step.append((bound_range, test_loss, i_step))\n",
    "        logger.info(f\"Single step values: {single_step_values}\")\n",
    "\n",
    "        results_dict_single_rep = {\n",
    "            \"meta_prompts\": meta_prompts_dict,\n",
    "            \"raw_outputs\": raw_outputs_dict,\n",
    "            \"old_value_pairs_with_i_step\": old_value_pairs_with_i_step,\n",
    "        }\n",
    "        results_dict[i_rep] = results_dict_single_rep\n",
    "        with open(results_json_path, \"w\") as f:\n",
    "            json.dump(results_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions: \n",
    "1. how to set HEBO Configs?\n",
    "2. how to treat value out of default range?\n",
    "3. how to refine the structure of old_value_pairs_substr rendered in prommpt?\n",
    "4. error occurs when compute GPs like:\n",
    "install from source\n",
    "    - cholesky_cpu: 16 of 16 elements of the torch.Size([4, 4]) tensor are NaN.\n",
    "    - Matrix not positive definite after repeatedly adding jitter up to 1.0e-04."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regret plot (bosteps, best function value)\n",
    "\n",
    "another plot the changes of recommendations\n",
    "\n",
    "the order of suggestions( random, loss value)\n",
    "\n",
    "format the code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.quasirandom import SobolEngine\n",
    "from hebo.design_space.design_space import DesignSpace\n",
    "from hebo.acquisitions.acq import MACE\n",
    "from hebo.acq_optimizers.evolution_optimizer import EvolutionOpt\n",
    "from hebo.optimizers.abstract_optimizer import AbstractOptimizer\n",
    "from typing import Optional\n",
    "\n",
    "class RandomSearch(AbstractOptimizer):\n",
    "    support_parallel_opt = True\n",
    "    support_combinatorial = True\n",
    "    support_contextual = True\n",
    "\n",
    "    def __init__(self, space, rand_sample: Optional[int] = None, scramble_seed: Optional[int] = None):\n",
    "        super().__init__(space)\n",
    "        self.space = space\n",
    "        self.X = pd.DataFrame(columns=self.space.para_names)\n",
    "        self.y = np.zeros((0, 1))\n",
    "        self.rand_sample = 1 + self.space.num_paras if rand_sample is None else max(2, rand_sample)\n",
    "        self.scramble_seed = scramble_seed\n",
    "        self.sobol = SobolEngine(self.space.num_paras, scramble=True, seed=scramble_seed)\n",
    "\n",
    "    def quasi_sample(self, n, fix_input=None):\n",
    "        samp = self.sobol.draw(n)\n",
    "        samp = samp * (self.space.opt_ub - self.space.opt_lb) + self.space.opt_lb\n",
    "        x = samp[:, :self.space.num_numeric]\n",
    "        xe = samp[:, self.space.num_numeric:]\n",
    "        for i, n in enumerate(self.space.numeric_names):\n",
    "            if self.space.paras[n].is_discrete_after_transform:\n",
    "                x[:, i] = x[:, i].round()\n",
    "        df_samp = self.space.inverse_transform(x, xe)\n",
    "        if fix_input is not None:\n",
    "            for k, v in fix_input.items():\n",
    "                df_samp[k] = v\n",
    "        return df_samp\n",
    "\n",
    "    def suggest(self, n_suggestions=1, fix_input=None):\n",
    "        sample = self.quasi_sample(n_suggestions, fix_input)\n",
    "        return sample\n",
    "\n",
    "    def observe(self, X, y):\n",
    "        \n",
    "        valid_id = np.where(np.isfinite(y.reshape(-1)))[0].tolist()\n",
    "        XX = X.iloc[valid_id]\n",
    "        yy = y[valid_id].reshape(-1, 1)\n",
    "        self.X = pd.concat([self.X, XX], axis=0, ignore_index=True)\n",
    "        self.y = np.vstack([self.y, yy])\n",
    "\n",
    "    @property\n",
    "    def best_x(self) -> pd.DataFrame:\n",
    "        if self.X.shape[0] == 0:\n",
    "            raise RuntimeError('No data has been observed!')\n",
    "        else:\n",
    "            return self.X.iloc[[self.y.argmin()]]\n",
    "\n",
    "    @property\n",
    "    def best_y(self) -> float:\n",
    "        if self.X.shape[0] == 0:\n",
    "            raise RuntimeError('No data has been observed!')\n",
    "        else:\n",
    "            return self.y.min()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hebo.design_space.design_space import DesignSpace\n",
    "\n",
    "# Example Usage\n",
    "# Assuming 'space' is already defined as an instance of DesignSpace\n",
    "space = DesignSpace().parse([\n",
    "    {\"name\":\"learning_rate\", \"type\": \"num\", \"lb\": 0.001, \"ub\": 0.1},\n",
    "    {\"name\":\"batch_size\",\"type\": \"int\", \"lb\": 32, \"ub\": 128},\n",
    "    {\"name\":\"num_layers\", \"type\": \"int\", \"lb\": 1, \"ub\": 5},\n",
    "    # Add more hyperparameters as needed\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Search Optimizer\n",
    "def evaluate(cfg):\n",
    "    return 0.1\n",
    "opt = RandomSearch(space)\n",
    "\n",
    "# Number of suggestions to generate\n",
    "n_suggestions = 10\n",
    "\n",
    "# Get suggestions\n",
    "# suggestions = random_search.suggest(n_suggestions=n_suggestions)\n",
    "# Evaluate suggestions and observe\n",
    "# Assuming 'evaluate' is a function that takes a configuration and returns a performance score\n",
    "for i in range(10):\n",
    "    rec_x = opt.suggest(n_suggestions=1)\n",
    "    y = np.array([evaluate(rec_x)], dtype=np.float64).reshape(-1, 1)\n",
    "    opt.observe(rec_x, y)\n",
    "    print(rec_x)\n",
    "\n",
    "    # # Print the best configuration found\n",
    "    # print(\"Best configuration found:\")\n",
    "    # print(random_search.best_x)\n",
    "    # print(\"Best score:\", random_search.best_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom copy import deepcopy\\nimport warnings\\nimport string\\nfrom sklearn.model_selection import StratifiedKFold\\nfrom sklearn.metrics import roc_curve, auc\\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\\nfrom sklearn.ensemble import RandomForestClassifier\\nimport numpy as np\\nimport pandas as pd\\n\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nsns.set_theme(style=\"darkgrid\")\\n\\n\\nwarnings.filterwarnings(\\'ignore\\')\\n\\nSEED = 42\\n\\n# * Training set has **891** rows and test set has **418** rows\\n# * Training set have **12** features and test set have **11** features\\n# * One extra feature in training set is `Survived` feature, which is the target variable\\n\\n\\ndef concat_df(train_data, test_data):\\n    # Returns a concatenated df of training and test set\\n    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\\n\\n\\ndef divide_df(all_data):\\n    # Returns divided dfs of training and test set\\n    return all_data.loc[:890], all_data.loc[891:].drop([\\'Survived\\'], axis=1)\\n\\n\\ndf_train = pd.read_csv(\\'./train.csv\\')\\ndf_test = pd.read_csv(\\'./test.csv\\')\\ndf_all = concat_df(df_train, df_test)\\n\\ndf_train.name = \\'Training Set\\'\\ndf_test.name = \\'Test Set\\'\\ndf_all.name = \\'All Set\\'\\n\\ndfs = [df_train, df_test]\\n\\nprint(\\'Number of Training Examples = {}\\'.format(df_train.shape[0]))\\nprint(\\'Number of Test Examples = {}\\\\n\\'.format(df_test.shape[0]))\\nprint(\\'Training X Shape = {}\\'.format(df_train.shape))\\nprint(\\'Training y Shape = {}\\\\n\\'.format(df_train[\\'Survived\\'].shape[0]))\\nprint(\\'Test X Shape = {}\\'.format(df_test.shape))\\nprint(\\'Test y Shape = {}\\\\n\\'.format(df_test.shape[0]))\\nprint(df_train.columns)\\nprint(df_test.columns)\\n\\n# ## **1. Exploratory Data Analysis**\\n\\n# ### **1.1 Overview**\\n# * `PassengerId` is the unique id of the row and it doesn\\'t have any effect on target\\n# * `Survived` is the target variable we are trying to predict (**0** or **1**):\\n#     - **1 = Survived**\\n#     - **0 = Not Survived**\\n# * `Pclass` (Passenger Class) is the socio-economic status of the passenger and it is a categorical ordinal feature which has **3** unique values (**1**,  **2 **or **3**):\\n#     - **1 = Upper Class**\\n#     - **2 = Middle Class**\\n#     - **3 = Lower Class**\\n# * `Name`, `Sex` and `Age` are self-explanatory\\n# * `SibSp` is the total number of the passengers\\' siblings and spouse\\n# * `Parch` is the total number of the passengers\\' parents and children\\n# * `Ticket` is the ticket number of the passenger\\n# * `Fare` is the passenger fare\\n# * `Cabin` is the cabin number of the passenger\\n# * `Embarked` is port of embarkation and it is a categorical feature which has **3** unique values (**C**, **Q** or **S**):\\n#     - **C = Cherbourg**\\n#     - **Q = Queenstown**\\n#     - **S = Southampton**\\n# ### **1.2 Missing Values**\\n# As seen from below, some columns have missing values. `display_missing` function shows the count of missing values in every column in both training and test set.\\n# * Training set have missing values in `Age`, `Cabin` and `Embarked` columns\\n# * Test set have missing values in `Age`, `Cabin` and `Fare` columns\\n# It is convenient to work on concatenated training and test set while dealing with missing values, otherwise filled data may overfit to training or test set samples. The count of missing values in `Age`, `Embarked` and `Fare` are smaller compared to total sample, but roughly **80%** of the `Cabin` is missing. Missing values in `Age`, `Embarked` and `Fare` can be filled with descriptive statistical measures but that wouldn\\'t work for `Cabin`.\\n\\n\\ndf_all_ = deepcopy(df_all)\\nfor col in df_all_.columns:\\n    df_all_[col] = pd.to_numeric(df_all_[col], errors=\\'coerce\\')\\ndf_all_corr = df_all_.corr().abs().unstack().sort_values(\\n    kind=\"quicksort\", ascending=False).reset_index()\\ndf_all_corr.rename(columns={\"level_0\": \"Feature 1\",\\n                   \"level_1\": \"Feature 2\", 0: \\'Correlation Coefficient\\'}, inplace=True)\\ndf_all_corr[df_all_corr[\\'Feature 1\\'] == \\'Age\\']\\nage_by_pclass_sex = df_all.groupby([\\'Sex\\', \\'Pclass\\'])[\\'Age\\'].median()\\n\\nfor pclass in range(1, 4):\\n    for sex in [\\'female\\', \\'male\\']:\\n        print(\\'Median age of Pclass {} {}s: {}\\'.format(\\n            pclass, sex, age_by_pclass_sex.loc[sex, pclass]))\\nprint(\\'Median age of all passengers: {}\\'.format(df_all[\\'Age\\'].median()))\\n\\n# Function to fill missing \\'Age\\' values with group medians\\n\\ndef fill_age(row):\\n    if pd.isna(row[\\'Age\\']):\\n        return age_by_pclass_sex.loc[row[\\'Sex\\'], row[\\'Pclass\\']]\\n    else:\\n        return row[\\'Age\\']\\n\\n\\n# Apply the function to the DataFrame\\ndf_all[\\'Age\\'] = df_all.apply(fill_age, axis=1)\\n\\n# Verify the missing values are filled\\nprint(df_all.sample(10))\\n\\ndf_all[df_all[\\'Embarked\\'].isnull()]\\n\\ndf_all[\\'Embarked\\'] = df_all[\\'Embarked\\'].fillna(\\'S\\')\\n\\ndf_all[df_all[\\'Fare\\'].isnull()]\\n\\nmed_fare = df_all.groupby([\\'Pclass\\', \\'Parch\\', \\'SibSp\\']).Fare.median()[3][0][0]\\n# Filling the missing value in Fare with the median Fare of 3rd class alone passenger\\ndf_all[\\'Fare\\'] = df_all[\\'Fare\\'].fillna(med_fare)\\n\\n# Creating Deck column from the first letter of the Cabin column (M stands for Missing)\\ndf_all[\\'Deck\\'] = df_all[\\'Cabin\\'].apply(\\n    lambda s: s[0] if pd.notnull(s) else \\'M\\')\\n\\ndf_all_decks = df_all.groupby([\\'Deck\\', \\'Pclass\\']).count().drop(columns=[\\'Survived\\', \\'Sex\\', \\'Age\\', \\'SibSp\\', \\'Parch\\',\\n                                                                        \\'Fare\\', \\'Embarked\\', \\'Cabin\\', \\'PassengerId\\', \\'Ticket\\']).rename(columns={\\'Name\\': \\'Count\\'}).transpose()\\n\\n\\ndef get_pclass_dist(df):\\n\\n    # Creating a dictionary for every passenger class count in every deck\\n    deck_counts = {\\'A\\': {}, \\'B\\': {}, \\'C\\': {}, \\'D\\': {},\\n                   \\'E\\': {}, \\'F\\': {}, \\'G\\': {}, \\'M\\': {}, \\'T\\': {}}\\n    decks = df.columns.levels[0]\\n\\n    for deck in decks:\\n        for pclass in range(1, 4):\\n            try:\\n                count = df[deck][pclass][0]\\n                deck_counts[deck][pclass] = count\\n            except KeyError:\\n                deck_counts[deck][pclass] = 0\\n\\n    df_decks = pd.DataFrame(deck_counts)\\n    deck_percentages = {}\\n\\n    # Creating a dictionary for every passenger class percentage in every deck\\n    for col in df_decks.columns:\\n        deck_percentages[col] = [\\n            (count / df_decks[col].sum()) * 100 for count in df_decks[col]]\\n\\n    return deck_counts, deck_percentages\\n\\n\\nall_deck_count, all_deck_per = get_pclass_dist(df_all_decks)\\n\\n# Passenger in the T deck is changed to A\\nidx = df_all[df_all[\\'Deck\\'] == \\'T\\'].index\\ndf_all.loc[idx, \\'Deck\\'] = \\'A\\'\\n\\n\\ndf_all_decks_survived = df_all.groupby([\\'Deck\\', \\'Survived\\']).count().drop(columns=[\\'Sex\\', \\'Age\\', \\'SibSp\\', \\'Parch\\', \\'Fare\\',\\n                                                                                   \\'Embarked\\', \\'Pclass\\', \\'Cabin\\', \\'PassengerId\\', \\'Ticket\\']).rename(columns={\\'Name\\': \\'Count\\'}).transpose()\\n\\n\\ndef get_survived_dist(df):\\n\\n    # Creating a dictionary for every survival count in every deck\\n    surv_counts = {\\'A\\': {}, \\'B\\': {}, \\'C\\': {},\\n                   \\'D\\': {}, \\'E\\': {}, \\'F\\': {}, \\'G\\': {}, \\'M\\': {}}\\n    decks = df.columns.levels[0]\\n\\n    for deck in decks:\\n        for survive in range(0, 2):\\n            surv_counts[deck][survive] = df[deck][survive][0]\\n\\n    df_surv = pd.DataFrame(surv_counts)\\n    surv_percentages = {}\\n\\n    for col in df_surv.columns:\\n        surv_percentages[col] = [\\n            (count / df_surv[col].sum()) * 100 for count in df_surv[col]]\\n\\n    return surv_counts, surv_percentages\\n\\n\\ndf_all[\\'Deck\\'] = df_all[\\'Deck\\'].replace([\\'A\\', \\'B\\', \\'C\\'], \\'ABC\\')\\ndf_all[\\'Deck\\'] = df_all[\\'Deck\\'].replace([\\'D\\', \\'E\\'], \\'DE\\')\\ndf_all[\\'Deck\\'] = df_all[\\'Deck\\'].replace([\\'F\\', \\'G\\'], \\'FG\\')\\n\\n\\ndf_all.drop([\\'Cabin\\'], inplace=True, axis=1)\\n\\ndf_train, df_test = divide_df(df_all)\\ndfs = [df_train, df_test]\\n\\n\\n# ### **1.3 Target Distribution**\\n# * **38.38%** (342/891) of training set is **Class 1**\\n# * **61.62%** (549/891) of training set is **Class 0**\\n\\nsurvived = df_train[\\'Survived\\'].value_counts()[1]\\nnot_survived = df_train[\\'Survived\\'].value_counts()[0]\\nsurvived_per = survived / df_train.shape[0] * 100\\nnot_survived_per = not_survived / df_train.shape[0] * 100\\n\\n\\n# ### **1.4 Correlations**\\n# Features are highly correlated with each other and dependent to each other. The highest correlation between features is **0.549500** in training set and **0.577147** in test set (between `Fare` and `Pclass`). The other features are also highly correlated. There are **9** correlations in training set and **6** correlations in test set that are higher than **0.1**.\\ndf_all_ = deepcopy(df_all)\\ndf_train, df_test = divide_df(df_all_)\\ndf_train = df_train.drop([\\'PassengerId\\'], axis=1)\\ndf_test = df_test.drop([\\'PassengerId\\'], axis=1)\\n# Convert categorical columns to numerical using one-hot encoding\\n# Identify columns with string values\\nstring_columns = df_train.select_dtypes(include=[\\'object\\']).columns\\n# Initialize LabelEncoder\\nle = LabelEncoder()\\n# Apply LabelEncoder to each string column\\nfor col in string_columns:\\n    df_train[col] = le.fit_transform(df_train[col])\\ndf_train_corr = df_train.corr().abs().unstack().sort_values(\\n    kind=\"quicksort\", ascending=False).reset_index()\\ndf_train_corr.rename(columns={\"level_0\": \"Feature 1\",\\n                     \"level_1\": \"Feature 2\", 0: \\'Correlation Coefficient\\'}, inplace=True)\\ndf_train_corr.drop(df_train_corr.iloc[1::2].index, inplace=True)\\ndf_train_corr_nd = df_train_corr.drop(\\n    df_train_corr[df_train_corr[\\'Correlation Coefficient\\'] == 1.0].index)\\nfor col in string_columns:\\n    df_test[col] = le.fit_transform(df_test[col])\\ndf_test_corr = df_test.corr().abs().unstack().sort_values(\\n    kind=\"quicksort\", ascending=False).reset_index()\\ndf_test_corr.rename(columns={\"level_0\": \"Feature 1\",\\n                    \"level_1\": \"Feature 2\", 0: \\'Correlation Coefficient\\'}, inplace=True)\\ndf_test_corr.drop(df_test_corr.iloc[1::2].index, inplace=True)\\ndf_test_corr_nd = df_test_corr.drop(\\n    df_test_corr[df_test_corr[\\'Correlation Coefficient\\'] == 1.0].index)\\n\\n# #### **1.5.1 Continuous Features**\\n# Both of the continuous features (`Age` and `Fare`) have good split points and spikes for a decision tree to learn. One potential problem for both features is, the distribution has more spikes and bumps in training set, but it is smoother in test set. Model may not be able to generalize to test set because of this reason.\\n#\\n# * Distribution of `Age` feature clearly shows that children younger than 15 has a higher survival rate than any of the other age groups\\n# * In distribution of `Fare` feature, the survival rate is higher on distribution tails. The distribution also has positive skew because of the extremely large outliers\\n\\ndf_train, df_test = divide_df(df_all)\\nsurv = df_train[\\'Survived\\'] == 1\\n\\n# ### **1.6 Conclusion**\\n# Most of the features are correlated with each other. This relationship can be used to create new features with feature transformation and feature interaction. Target encoding could be very useful as well because of the high correlations with `Survived` feature.\\n#\\n# Split points and spikes are visible in continuous features. They can be captured easily with a decision tree model, but linear models may not be able to spot them.\\n#\\n# Categorical features have very distinct distributions with different survival rates. Those features can be one-hot encoded. Some of those features may be combined with each other to make new features.\\n#\\n# Created a new feature called `Deck` and dropped `Cabin` feature at the **Exploratory Data Analysis** part.\\n\\ndf_all = concat_df(df_train, df_test)\\n\\n# ## **2. Feature Engineering**\\n# ### **2.1 Binning Continuous Features**\\n# #### **2.1.1 Fare**\\n# `Fare` feature is positively skewed and survival rate is extremely high on the right end. **13** quantile based bins are used for `Fare` feature. Even though the bins are too much, they provide decent amount of information gain. The groups at the left side of the graph has the lowest survival rate and the groups at the right side of the graph has the highest survival rate. This high survival rate was not visible in the distribution graph. There is also an unusual group **(15.742, 23.25]** in the middle with high survival rate that is captured in this process.\\n\\ndf_all[\\'Fare\\'] = pd.qcut(df_all[\\'Fare\\'], 13)\\n\\n# #### **2.1.2 Age**\\n# `Age` feature has a normal distribution with some spikes and bumps and **10** quantile based bins are used for `Age`. The first bin has the highest survival rate and 4th bin has the lowest survival rate. Those were the biggest spikes in the distribution. There is also an unusual group **(34.0, 40.0]** with high survival rate that is captured in this process.\\ndf_all[\\'Age\\'] = pd.qcut(df_all[\\'Age\\'], 10)\\n\\n# ### **2.2 Frequency Encoding**\\n# `Family_Size` is created by adding `SibSp`, `Parch` and **1**. `SibSp` is the count of siblings and spouse, and `Parch` is the count of parents and children. Those columns are added in order to find the total size of families. Adding **1** at the end, is the current passenger. Graphs have clearly shown that family size is a predictor of survival because different values have different survival rates.\\n# * Family Size with **1** are labeled as **Alone**\\n# * Family Size with **2**, **3** and **4** are labeled as **Small**\\n# * Family Size with **5** and **6** are labeled as **Medium**\\n# * Family Size with **7**, **8** and **11** are labeled as **Large**\\n\\ndf_all[\\'Ticket_Frequency\\'] = df_all.groupby(\\n    \\'Ticket\\')[\\'Ticket\\'].transform(\\'count\\')\\ndf_all[\\'Family_Size\\'] = df_all[\\'SibSp\\'] + df_all[\\'Parch\\'] + 1\\nfamily_map = {1: \\'Alone\\', 2: \\'Small\\', 3: \\'Small\\', 4: \\'Small\\',\\n              5: \\'Medium\\', 6: \\'Medium\\', 7: \\'Large\\', 8: \\'Large\\', 11: \\'Large\\'}\\ndf_all[\\'Family_Size_Grouped\\'] = df_all[\\'Family_Size\\'].map(family_map)\\n\\n# ### **2.3 Title & Is Married**\\n# `Title` is created by extracting the prefix before `Name` feature. According to graph below, there are many titles that are occuring very few times. Some of those titles doesn\\'t seem correct and they need to be replaced. **Miss**, **Mrs**, **Ms**, **Mlle**, **Lady**, **Mme**, **the Countess**, **Dona** titles are replaced with **Miss/Mrs/Ms** because all of them are female. Values like **Mlle**, **Mme** and **Dona** are actually the name of the passengers, but they are classified as titles because `Name` feature is split by comma. **Dr**, **Col**, **Major**, **Jonkheer**, **Capt**, **Sir**, **Don** and **Rev** titles are replaced with **Dr/Military/Noble/Clergy** because those passengers have similar characteristics. **Master** is a unique title. It is given to male passengers below age **26**. They have the highest survival rate among all males.\\n#\\n# `Is_Married` is a binary feature based on the **Mrs** title. **Mrs** title has the highest survival rate among other female titles. This title needs to be a feature because all female titles are grouped with each other.\\n\\ndf_all[\\'Title\\'] = df_all[\\'Name\\'].str.split(\\n    \\', \\', expand=True)[1].str.split(\\'.\\', expand=True)[0]\\ndf_all[\\'Is_Married\\'] = 0\\ndf_all[\\'Is_Married\\'].loc[df_all[\\'Title\\'] == \\'Mrs\\'] = 1\\ndf_all[\\'Title\\'] = df_all[\\'Title\\'].replace(\\n    [\\'Miss\\', \\'Mrs\\', \\'Ms\\', \\'Mlle\\', \\'Lady\\', \\'Mme\\', \\'the Countess\\', \\'Dona\\'], \\'Miss/Mrs/Ms\\')\\ndf_all[\\'Title\\'] = df_all[\\'Title\\'].replace(\\n    [\\'Dr\\', \\'Col\\', \\'Major\\', \\'Jonkheer\\', \\'Capt\\', \\'Sir\\', \\'Don\\', \\'Rev\\'], \\'Dr/Military/Noble/Clergy\\')\\n\\n\\n# ### **2.4 Target Encoding**\\n# `extract_surname` function is used for extracting surnames of passengers from the `Name` feature. `Family` feature is created with the extracted surname. This is necessary for grouping passengers in the same family.\\n\\ndef extract_surname(data):\\n\\n    families = []\\n\\n    for i in range(len(data)):\\n        name = data.iloc[i]\\n\\n        if \\'(\\' in name:\\n            name_no_bracket = name.split(\\'(\\')[0]\\n        else:\\n            name_no_bracket = name\\n\\n        family = name_no_bracket.split(\\',\\')[0]\\n        title = name_no_bracket.split(\\',\\')[1].strip().split(\\' \\')[0]\\n\\n        for c in string.punctuation:\\n            family = family.replace(c, \\'\\').strip()\\n\\n        families.append(family)\\n\\n    return families\\n\\n\\ndf_all[\\'Family\\'] = extract_surname(df_all[\\'Name\\'])\\ndf_train = df_all.loc[:890]\\ndf_test = df_all.loc[891:]\\ndfs = [df_train, df_test]\\n\\n\\n# `Family_Survival_Rate` is calculated from families in training set since there is no `Survived` feature in test set. A list of family names that are occuring in both training and test set (`non_unique_families`), is created. The survival rate is calculated for families with more than 1 members in that list, and stored in `Family_Survival_Rate` feature.\\n#\\n# An extra binary feature `Family_Survival_Rate_NA` is created for families that are unique to the test set. This feature is also necessary because there is no way to calculate those families\\' survival rate. This feature implies that family survival rate is not applicable to those passengers because there is no way to retrieve their survival rate.\\n#\\n# `Ticket_Survival_Rate` and `Ticket_Survival_Rate_NA` features are also created with the same method. `Ticket_Survival_Rate` and `Family_Survival_Rate` are averaged and become `Survival_Rate`, and `Ticket_Survival_Rate_NA` and `Family_Survival_Rate_NA` are also averaged and become `Survival_Rate_NA`.\\n\\n# Creating a list of families and tickets that are occuring in both training and test set\\nnon_unique_families = [\\n    x for x in df_train[\\'Family\\'].unique() if x in df_test[\\'Family\\'].unique()]\\nnon_unique_tickets = [\\n    x for x in df_train[\\'Ticket\\'].unique() if x in df_test[\\'Ticket\\'].unique()]\\n\\ndf_family_survival_rate = df_train.groupby(\\n    \\'Family\\')[[\\'Survived\\', \\'Family_Size\\']].median()\\ndf_ticket_survival_rate = df_train.groupby(\\n    \\'Ticket\\')[[\\'Survived\\', \\'Ticket_Frequency\\']].median()\\n\\nfamily_rates = {}\\nticket_rates = {}\\n\\nfor i in range(len(df_family_survival_rate)):\\n    # Checking a family exists in both training and test set, and has members more than 1\\n    if df_family_survival_rate.index[i] in non_unique_families and df_family_survival_rate.iloc[i, 1] > 1:\\n        family_rates[df_family_survival_rate.index[i]\\n                     ] = df_family_survival_rate.iloc[i, 0]\\n\\nfor i in range(len(df_ticket_survival_rate)):\\n    # Checking a ticket exists in both training and test set, and has members more than 1\\n    if df_ticket_survival_rate.index[i] in non_unique_tickets and df_ticket_survival_rate.iloc[i, 1] > 1:\\n        ticket_rates[df_ticket_survival_rate.index[i]\\n                     ] = df_ticket_survival_rate.iloc[i, 0]\\n\\nmean_survival_rate = np.mean(df_train[\\'Survived\\'])\\n\\ntrain_family_survival_rate = []\\ntrain_family_survival_rate_NA = []\\ntest_family_survival_rate = []\\ntest_family_survival_rate_NA = []\\n\\nfor i in range(len(df_train)):\\n    if df_train[\\'Family\\'][i] in family_rates:\\n        train_family_survival_rate.append(family_rates[df_train[\\'Family\\'][i]])\\n        train_family_survival_rate_NA.append(1)\\n    else:\\n        train_family_survival_rate.append(mean_survival_rate)\\n        train_family_survival_rate_NA.append(0)\\n\\nfor i in range(len(df_test)):\\n    if df_test[\\'Family\\'].iloc[i] in family_rates:\\n        test_family_survival_rate.append(\\n            family_rates[df_test[\\'Family\\'].iloc[i]])\\n        test_family_survival_rate_NA.append(1)\\n    else:\\n        test_family_survival_rate.append(mean_survival_rate)\\n        test_family_survival_rate_NA.append(0)\\n\\ndf_train[\\'Family_Survival_Rate\\'] = train_family_survival_rate\\ndf_train[\\'Family_Survival_Rate_NA\\'] = train_family_survival_rate_NA\\ndf_test[\\'Family_Survival_Rate\\'] = test_family_survival_rate\\ndf_test[\\'Family_Survival_Rate_NA\\'] = test_family_survival_rate_NA\\n\\ntrain_ticket_survival_rate = []\\ntrain_ticket_survival_rate_NA = []\\ntest_ticket_survival_rate = []\\ntest_ticket_survival_rate_NA = []\\n\\nfor i in range(len(df_train)):\\n    if df_train[\\'Ticket\\'][i] in ticket_rates:\\n        train_ticket_survival_rate.append(ticket_rates[df_train[\\'Ticket\\'][i]])\\n        train_ticket_survival_rate_NA.append(1)\\n    else:\\n        train_ticket_survival_rate.append(mean_survival_rate)\\n        train_ticket_survival_rate_NA.append(0)\\n\\nfor i in range(len(df_test)):\\n    if df_test[\\'Ticket\\'].iloc[i] in ticket_rates:\\n        test_ticket_survival_rate.append(\\n            ticket_rates[df_test[\\'Ticket\\'].iloc[i]])\\n        test_ticket_survival_rate_NA.append(1)\\n    else:\\n        test_ticket_survival_rate.append(mean_survival_rate)\\n        test_ticket_survival_rate_NA.append(0)\\n\\ndf_train[\\'Ticket_Survival_Rate\\'] = train_ticket_survival_rate\\ndf_train[\\'Ticket_Survival_Rate_NA\\'] = train_ticket_survival_rate_NA\\ndf_test[\\'Ticket_Survival_Rate\\'] = test_ticket_survival_rate\\ndf_test[\\'Ticket_Survival_Rate_NA\\'] = test_ticket_survival_rate_NA\\n\\nfor df in [df_train, df_test]:\\n    df[\\'Survival_Rate\\'] = (df[\\'Ticket_Survival_Rate\\'] +\\n                           df[\\'Family_Survival_Rate\\']) / 2\\n    df[\\'Survival_Rate_NA\\'] = (\\n        df[\\'Ticket_Survival_Rate_NA\\'] + df[\\'Family_Survival_Rate_NA\\']) / 2\\n\\n# ### **2.5 Feature Transformation**\\n\\n# #### **2.5.1 Label Encoding Non-Numerical Features**\\n# `Embarked`, `Sex`, `Deck` , `Title` and `Family_Size_Grouped` are object type, and `Age` and `Fare` features are category type. They are converted to numerical type with `LabelEncoder`. `LabelEncoder` basically labels the classes from **0** to **n**. This process is necessary for models to learn from those features.\\n\\n\\nnon_numeric_features = [\\'Embarked\\', \\'Sex\\', \\'Deck\\',\\n                        \\'Title\\', \\'Family_Size_Grouped\\', \\'Age\\', \\'Fare\\']\\n\\nfor df in dfs:\\n    for feature in non_numeric_features:\\n        df[feature] = LabelEncoder().fit_transform(df[feature])\\n\\n# #### **2.5.2 One-Hot Encoding the Categorical Features**\\n# The categorical features (`Pclass`, `Sex`, `Deck`, `Embarked`, `Title`) are converted to one-hot encoded features with `OneHotEncoder`. `Age` and `Fare` features are not converted because they are ordinal unlike the previous ones.\\n\\ncat_features = [\\'Pclass\\', \\'Sex\\', \\'Deck\\',\\n                \\'Embarked\\', \\'Title\\', \\'Family_Size_Grouped\\']\\nencoded_features = []\\n\\nfor df in dfs:\\n    for feature in cat_features:\\n        encoded_feat = OneHotEncoder().fit_transform(\\n            df[feature].values.reshape(-1, 1)).toarray()\\n        n = df[feature].nunique()\\n        cols = [\\'{}_{}\\'.format(feature, n) for n in range(1, n + 1)]\\n        encoded_df = pd.DataFrame(encoded_feat, columns=cols)\\n        encoded_df.index = df.index\\n        encoded_features.append(encoded_df)\\n\\ndf_train = pd.concat([df_train, *encoded_features[:6]], axis=1)\\ndf_test = pd.concat([df_test, *encoded_features[6:]], axis=1)\\n\\n# ### **2.6 Conclusion**\\n# `Age` and `Fare` features are binned. Binning helped dealing with outliers and it revealed some homogeneous groups in those features. `Family_Size` is created by adding `Parch` and `SibSp` features and **1**. `Ticket_Frequency` is created by counting the occurence of `Ticket` values.\\n#\\n# `Name` feature is very useful. First, `Title` and `Is_Married` features are created from the title prefix in the names. Second, `Family_Survival_Rate` and `Family_Survival_Rate_NA`  features are created by target encoding the surname of the passengers. `Ticket_Survival_Rate` is created by target encoding the `Ticket` feature. `Survival_Rate` feature is created by averaging the `Family_Survival_Rate` and `Ticket_Survival_Rate` features.\\n#\\n# Finally, the non-numeric type features are label encoded and categorical features are one-hot encoded. Created **5** new features (`Family_Size`, `Title`, `Is_Married`, `Survival_Rate` and `Survival_Rate_NA`) and dropped the useless features after encoding.\\n\\ndf_all = concat_df(df_train, df_test)\\ndrop_cols = [\\'Deck\\', \\'Embarked\\', \\'Family\\', \\'Family_Size\\', \\'Family_Size_Grouped\\', \\'Survived\\',\\n             \\'Name\\', \\'Parch\\', \\'PassengerId\\', \\'Pclass\\', \\'Sex\\', \\'SibSp\\', \\'Ticket\\', \\'Title\\',\\n             \\'Ticket_Survival_Rate\\', \\'Family_Survival_Rate\\', \\'Ticket_Survival_Rate_NA\\', \\'Family_Survival_Rate_NA\\']\\n\\ndf_all.drop(columns=drop_cols, inplace=True)\\n\\n',\n",
       " \"\\n\\nX_train = StandardScaler().fit_transform(df_train.drop(columns=drop_cols))\\ny_train = df_train['Survived'].values\\nX_test = StandardScaler().fit_transform(df_test.drop(columns=drop_cols))\\n\\n# ### **3.1 Random Forest**\\n\\nsingle_best_model = RandomForestClassifier(criterion='gini',\\n                                           n_estimators=1100,\\n                                           max_depth=5,\\n                                           min_samples_split=4,\\n                                           min_samples_leaf=5,\\n                                           max_features='auto',\\n                                           oob_score=True,\\n                                           random_state=SEED,\\n                                           n_jobs=-1,\\n                                           verbose=1)\\n\\n\\n# `StratifiedKFold` is used for stratifying the target variable. The folds are made by preserving the percentage of samples for each class in target variable (`Survived`).\\n\\nN = 5\\noob = 0\\nprobs = pd.DataFrame(np.zeros((len(X_test), N * 2)), columns=[\\n                     'Fold_{}_Prob_{}'.format(i, j) for i in range(1, N + 1) for j in range(2)])\\nimportances = pd.DataFrame(np.zeros((X_train.shape[1], N)), columns=[\\n                           'Fold_{}'.format(i) for i in range(1, N + 1)], index=df_all.columns)\\nfprs, tprs, scores = [], [], []\\n\\nskf = StratifiedKFold(n_splits=N, random_state=N, shuffle=True)\\n\\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\\n    print('Fold {}\\\\n'.format(fold))\\n\\n    # Fitting the model\\n    single_best_model.fit(X_train[trn_idx], y_train[trn_idx])\\n\\n    # Computing Train AUC score\\n    trn_fpr, trn_tpr, trn_thresholds = roc_curve(\\n        y_train[trn_idx], single_best_model.predict_proba(X_train[trn_idx])[:, 1])\\n    trn_auc_score = auc(trn_fpr, trn_tpr)\\n    # Computing Validation AUC score\\n    val_fpr, val_tpr, val_thresholds = roc_curve(\\n        y_train[val_idx], single_best_model.predict_proba(X_train[val_idx])[:, 1])\\n    val_auc_score = auc(val_fpr, val_tpr)\\n\\n    scores.append((trn_auc_score, val_auc_score))\\n    fprs.append(val_fpr)\\n    tprs.append(val_tpr)\\n\\n    # X_test probabilities\\n    probs.loc[:, 'Fold_{}_Prob_0'.format(\\n        fold)] = single_best_model.predict_proba(X_test)[:, 0]\\n    probs.loc[:, 'Fold_{}_Prob_1'.format(\\n        fold)] = single_best_model.predict_proba(X_test)[:, 1]\\n    importances.iloc[:, fold - 1] = single_best_model.feature_importances_\\n\\n    oob += single_best_model.oob_score_ / N\\n    print('Fold {} OOB Score: {}\\\\n'.format(fold, single_best_model.oob_score_))\\nprint('Average OOB Score: {}'.format(oob))\\n\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import torch\n",
    "import json_repair\n",
    "from pathlib import Path\n",
    "ROOT_PATH = Path.cwd().resolve()\n",
    "\n",
    "from loguru import logger\n",
    "from banks import Prompt\n",
    "import math\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "import functools\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from hebo.design_space.design_space import DesignSpace\n",
    "from hebo.optimizers.hebo import HEBO\n",
    "from hebo.optimizers.bo import BO\n",
    "import ConfigSpace\n",
    "from random_search import RandomSearch\n",
    "from hpobench.benchmarks.ml.xgboost_benchmark_old import XGBoostBenchmark\n",
    "import time\n",
    "from hpobench.util.openml_data_manager import get_openmlcc18_taskids\n",
    "import asyncio\n",
    "import prompt_utils\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import openai\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "RANDOM_SEED=42\n",
    "\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)  # If using GPU\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "def parse_json(rsp):\n",
    "    pass\n",
    "\n",
    "def parse_code(rsp):\n",
    "    pass\n",
    "\n",
    "script_path=ROOT_PATH / 'kaggle/titanic/titanic.py'\n",
    "\n",
    "optimizer_gpt_max_decode_steps = 1024\n",
    "optimizer_gpt_temperature = 1.0\n",
    "\n",
    "optimizer_llm_dict = dict()\n",
    "optimizer_llm_dict[\"max_decode_steps\"] = optimizer_gpt_max_decode_steps\n",
    "optimizer_llm_dict[\"temperature\"] = optimizer_gpt_temperature\n",
    "\n",
    "\n",
    "call_optimizer_server_func = functools.partial(\n",
    "    prompt_utils.call_openai_server_func,\n",
    "    model='gpt-3.5-turbo',\n",
    "    max_decode_steps=optimizer_gpt_max_decode_steps,\n",
    "    temperature=optimizer_gpt_temperature,\n",
    ")\n",
    "\n",
    "# # ====================== try calling the servers ============================\n",
    "# print(\"\\n======== testing the optimizer server ===========\")\n",
    "# optimizer_test_output = call_optimizer_server_func(\n",
    "#     \"Does the sun rise from the north? Just answer yes or no.\",\n",
    "#     temperature=1.0\n",
    "# )\n",
    "# print(f\"optimizer test output: {optimizer_test_output}\")\n",
    "# print(\"Finished testing the optimizer server.\")\n",
    "# print(\"\\n=================================================\")\n",
    "\n",
    "with open(script_path,'r') as f:\n",
    "    script=f.read()\n",
    "\n",
    "data_part,model_part=script.split('### Model ###')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_prompt='''\n",
    "## Data related code ##\n",
    "{code}\n",
    "\n",
    "As an experienced data scientist, please summarize the main aspects of the code provided. Your summary should include:\n",
    "\n",
    "Key Steps: Describe the primary steps and processes carried out in the code.\n",
    "Key Findings: Highlight the main results or outcomes derived from the code.\n",
    "Your summary should be formal and clear.\n",
    "'''\n",
    "\n",
    "search_space_prompt='''\n",
    "## Data preprocessing report ## \n",
    "{report}\n",
    "## ML model docstring ##\n",
    "{docstring}\n",
    "\n",
    "You are an experienced machine learning engineer. Using the data preprocessing report and the ML model's docstring, identify key hyperparameters that should be optimized through Bayesian Optimization (BO). For each hyperparameter you identify, specify it and recommend a corresponding search space.\n",
    "\n",
    "Answer in the following format:\n",
    "```json\n",
    "{\n",
    "  \"hp_name\": \"name of the hyperparameter\",\n",
    "  \"hp_type\": \"choose from [int, num (float), bool, pow (varies in log space), cat (categorical value)]\",\n",
    "  \"search_space\": [\"lower_bound\", \"upper_bound\"] if numerical values, else [\"categorical_list\"]\n",
    "}\n",
    "```\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
